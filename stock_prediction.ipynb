{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Prediction using RNN and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-02T01:42:02.277649200Z",
     "start_time": "2023-12-02T01:42:02.253312500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                date      open       low     close  adj close     volume\nDate            Open      High       Low     Close  Adj Close     Volume\n2003-11-03  0.407679  0.416071  0.406786  0.413393   0.350425  302842400\n2003-11-04  0.411964  0.412500  0.403393  0.409107   0.346792  249233600\n2003-11-05  0.407500  0.413036  0.401250  0.411250   0.348608  322470400\n2003-11-06  0.409107  0.413393  0.404464  0.412857   0.349971  397073600",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>low</th>\n      <th>close</th>\n      <th>adj close</th>\n      <th>volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Date</th>\n      <td>Open</td>\n      <td>High</td>\n      <td>Low</td>\n      <td>Close</td>\n      <td>Adj Close</td>\n      <td>Volume</td>\n    </tr>\n    <tr>\n      <th>2003-11-03</th>\n      <td>0.407679</td>\n      <td>0.416071</td>\n      <td>0.406786</td>\n      <td>0.413393</td>\n      <td>0.350425</td>\n      <td>302842400</td>\n    </tr>\n    <tr>\n      <th>2003-11-04</th>\n      <td>0.411964</td>\n      <td>0.412500</td>\n      <td>0.403393</td>\n      <td>0.409107</td>\n      <td>0.346792</td>\n      <td>249233600</td>\n    </tr>\n    <tr>\n      <th>2003-11-05</th>\n      <td>0.407500</td>\n      <td>0.413036</td>\n      <td>0.401250</td>\n      <td>0.411250</td>\n      <td>0.348608</td>\n      <td>322470400</td>\n    </tr>\n    <tr>\n      <th>2003-11-06</th>\n      <td>0.409107</td>\n      <td>0.413393</td>\n      <td>0.404464</td>\n      <td>0.412857</td>\n      <td>0.349971</td>\n      <td>397073600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "apple_stock_data = pd.read_csv(\"AAPL.csv\", names=['date', 'open', 'low', 'close', 'adj close', 'volume'])\n",
    "apple_stock_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# reprocess_data \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_data(data):\n",
    "\n",
    "    # Handling missing values\n",
    "    data.fillna(method='ffill', inplace=True)  # Fill missing values with the previous value\n",
    "\n",
    "    # Feature Engineering: Adding moving average as an example\n",
    "    data['moving_average'] = data['close'].rolling(window=5).mean()\n",
    "\n",
    "    # Scaling\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data[['open', 'low', 'close', 'adj close', 'volume', 'moving_average']])\n",
    "\n",
    "    # Sequence Creation\n",
    "    def create_sequences(data, sequence_length):\n",
    "        xs, ys = [], []\n",
    "        for i in range(len(data) - sequence_length):\n",
    "            x = data[i:(i + sequence_length)]\n",
    "            y = data[i + sequence_length][2]  # Assuming 'close' price is the target\n",
    "            xs.append(x)\n",
    "            ys.append(y)\n",
    "        return np.array(xs), np.array(ys)\n",
    "\n",
    "    sequence_length = 60  # Number of days for the sequence\n",
    "    return create_sequences(scaled_data, sequence_length)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T01:43:15.623245900Z",
     "start_time": "2023-12-02T01:43:15.607352500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# data split\n",
    "def split_data(features, labels, train_size_percentage=0.8):\n",
    "    # Calculate the index to split the data\n",
    "    train_size = int(len(features) * train_size_percentage)\n",
    "\n",
    "    # Split the data\n",
    "    train_features = features[:train_size]\n",
    "    train_labels = labels[:train_size]\n",
    "    validation_features = features[train_size:]\n",
    "    validation_labels = labels[train_size:]\n",
    "\n",
    "    return (train_features, train_labels), (validation_features, validation_labels)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T01:45:29.981929400Z",
     "start_time": "2023-12-02T01:45:29.974975900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# rnn model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional\n",
    "\n",
    "def create_enhanced_rnn_model(input_shape):\n",
    "    rnn_model = Sequential()\n",
    "\n",
    "    # Adding Bidirectional LSTM layers for better temporal learning\n",
    "    rnn_model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "    rnn_model.add(Dropout(0.25))\n",
    "    rnn_model.add(BatchNormalization())\n",
    "\n",
    "    rnn_model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    rnn_model.add(Dropout(0.25))\n",
    "    rnn_model.add(BatchNormalization())\n",
    "\n",
    "    rnn_model.add(Bidirectional(LSTM(128)))\n",
    "    rnn_model.add(Dropout(0.25))\n",
    "    rnn_model.add(BatchNormalization())\n",
    "\n",
    "    # Adding more Dense layers for complexity\n",
    "    rnn_model.add(Dense(64, activation='relu'))\n",
    "    rnn_model.add(Dropout(0.25))\n",
    "\n",
    "    rnn_model.add(Dense(32, activation='relu'))\n",
    "    rnn_model.add(Dropout(0.25))\n",
    "\n",
    "    # Output layer\n",
    "    rnn_model.add(Dense(1, activation='linear'))  # Assuming a regression problem for stock price prediction\n",
    "\n",
    "    return rnn_model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T02:03:30.707552300Z",
     "start_time": "2023-12-02T02:03:30.698612200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# cnn model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Activation, Flatten\n",
    "\n",
    "def create_enhanced_cnn_model(input_shape):\n",
    "    cnn_model = Sequential()\n",
    "\n",
    "    # Adjusting the number of filters and kernel size\n",
    "    cnn_model.add(Conv1D(64, 5, activation='relu', input_shape=input_shape))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "\n",
    "    cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "\n",
    "    cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "    cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "\n",
    "    cnn_model.add(Flatten())\n",
    "\n",
    "    # Adding more Dense layers\n",
    "    cnn_model.add(Dense(64, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "\n",
    "    cnn_model.add(Dense(32, activation='relu'))\n",
    "    cnn_model.add(Dropout(0.25))\n",
    "\n",
    "    # Output layer\n",
    "    cnn_model.add(Dense(1, activation='linear'))  # Assuming a regression problem for stock price prediction\n",
    "\n",
    "    cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return cnn_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-02T02:03:35.493794300Z",
     "start_time": "2023-12-02T02:03:35.485847400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training the Enhanced RNN Model\n",
    "rnn_model = create_enhanced_rnn_model(train_features.shape[1:])\n",
    "rnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "rnn_history = rnn_model.fit(\n",
    "    train_features, train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_features, validation_labels)\n",
    ")\n",
    "\n",
    "# Training the Enhanced CNN Model\n",
    "cnn_model = create_enhanced_cnn_model(train_features.shape[1:])\n",
    "cnn_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "cnn_history = cnn_model.fit(\n",
    "    train_features, train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_features, validation_labels)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
